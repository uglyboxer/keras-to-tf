{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cole/.virtualenvs/keras-to-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/cole/.virtualenvs/keras-to-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/cole/.virtualenvs/keras-to-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/cole/.virtualenvs/keras-to-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/cole/.virtualenvs/keras-to-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/cole/.virtualenvs/keras-to-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from copy import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "sess = tf.Session()\n",
    "keras.backend.set_session(sess)\n",
    "tf.keras.backend.set_session(sess)\n",
    "tf.keras.backend._LEARNING_PHASE = tf.constant(0)\n",
    "tf.keras.backend.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/cole/.virtualenvs/keras-to-tf/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/cole/.virtualenvs/keras-to-tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/cole/.virtualenvs/keras-to-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/cole/.virtualenvs/keras-to-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cole/.virtualenvs/keras-to-tf/lib/python3.7/site-packages/keras/engine/saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "orig_model = keras.models.load_model('model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove2word2vec(glove_input_file=\"data/glove.6B.50d.txt\", word2vec_output_file=\"data/gensim_glove_vectors.txt\")\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "wv = KeyedVectors.load_word2vec_format(\"data/gensim_glove_vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for i in range(100):\n",
    "    test.append(wv['python'])\n",
    "test = np.array(test).reshape(1, 100, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39491233]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe not necessary, but let's force everything into tf.keras\n",
    "\n",
    "def convert_to_tf(model, name):    \n",
    "    model.name = '{}'.format(str(name).lower().replace('(', '')\n",
    "                                              .replace(')', '')\n",
    "                                              .replace(',', '')\n",
    "                                              .replace('/', '_')\n",
    "                                              .replace(' ', '_'))\n",
    "    js = model.to_json()\n",
    "    filepath = '/tmp/{}_weights.h5'.format(model.name)\n",
    "    model.save_weights(filepath)\n",
    "    new_model = tf.keras.models.model_from_json(js)\n",
    "    new_model.load_weights(filepath)\n",
    "\n",
    "    models_dir = 'models'\n",
    "    if not os.path.exists(models_dir):\n",
    "        os.makedirs(models_dir)\n",
    "    \n",
    "    new_model.save('{}/{}.h5'.format(models_dir, model.name))\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_orig_model = convert_to_tf(orig_model, 'cnn_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wv_embedding_layer(wv, oov_vector_file, pad_string='--PAD--', max_sequence_length=100):\n",
    "    \"\"\"\n",
    "    From an existing gensim word2vec model create a tf.keras embedding layer to use ahead of pretrained models in tf serving\n",
    "    Pad string will assigned a vector of zeros\n",
    "    Out of Vocabulary vector would've been predefined when original model was created.  We need to keep it around.\n",
    "\n",
    "\n",
    "    When saving a combined model:\n",
    "        signature = tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "            inputs={'image': model.input}, outputs={'scores': model.output}\n",
    "            )\n",
    "        builder = tf.saved_model.builder.SavedModelBuilder('/tmp/wvmodel7')\n",
    "        builder.add_meta_graph_and_variables(\n",
    "            sess=K.get_session(),\n",
    "            tags=[tf.saved_model.tag_constants.SERVING],\n",
    "            signature_def_map={tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature},\n",
    "            legacy_init_op=tf.tables_initializer()\n",
    "            )\n",
    "        builder.save()\n",
    "\n",
    "    Args:\n",
    "        wv                                  gensim word vector model\n",
    "        oov_token_file                      str\n",
    "        pad_string                          str\n",
    "        max_sequence_lenght                 str\n",
    "\n",
    "    Returns:\n",
    "        tf.keras model that will take tokens as strings and return a matrix of word vectors\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the oov token\n",
    "    with open(oov_vector_file, 'rb') as f:\n",
    "        oov_vec = pickle.load(f)\n",
    "\n",
    "\n",
    "    # Construct new index to word mapping\n",
    "    index2word = copy(wv.index2word)\n",
    "    index2word.append(pad_string)\n",
    "\n",
    "    # Build the embedding matrix\n",
    "    embedding_dim = wv[wv.index2word[0]].shape[0]\n",
    "    embedding_matrix = np.zeros((len(wv.index2word) + 2, embedding_dim))  # +2 because 1 for pad token, 1 for oov\n",
    "    for i, word in enumerate(wv.index2word):  # use the original lookup index as it doesn't have a pad token\n",
    "        embedding_vector = wv[word]\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    # Set the last entry to the oov_token\n",
    "    embedding_matrix[len(embedding_matrix) - 1] = oov_vec\n",
    "\n",
    "    # Build the tf lookup table\n",
    "    lookup_op = tf.contrib.lookup.index_table_from_tensor(tf.constant(index2word),  # not wv.index2word as we want the pad token\n",
    "                                                          default_value=len(embedding_matrix) - 1,\n",
    "                                                          name='lookup_op')  # points to the oov/unk token\n",
    "\n",
    "\n",
    "    # Build the tf.keras Embedding layer\n",
    "    embedding_layer = tf.keras.layers.Embedding(len(wv.index2word) + 2,\n",
    "                                             embedding_dim,\n",
    "                                             weights=[embedding_matrix],\n",
    "                                             input_length=max_sequence_length,\n",
    "                                             trainable=False,\n",
    "                                             name='embedding_layer')\n",
    "\n",
    "    # Build a model that takes tokens\n",
    "    _input = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.string, name='wv_in')\n",
    "    x = tf.keras.layers.Lambda(lookup_op.lookup, output_shape=(max_sequence_length,), name='lambda_lookup')(_input)\n",
    "    x = embedding_layer(x)\n",
    "    wv_model = tf.keras.models.Model(_input, x)  # Everything in tf.keras please\n",
    "\n",
    "    lookup_op.init.run(session=tf.keras.backend.get_session())\n",
    "\n",
    "#     tf.compat.v1.tables_initializer().run(session=tf.keras.backend.get_session())\n",
    "\n",
    "    \n",
    "\n",
    "    return wv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/cole/.virtualenvs/keras-to-tf/lib/python3.7/site-packages/tensorflow/python/ops/lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-8-8a4aac12fa7f>:72: InitializableLookupTableBase.init (from tensorflow.python.ops.lookup_ops) is deprecated and will be removed after 2018-12-15.\n",
      "Instructions for updating:\n",
      "Use `initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "OOV_VECTOR_FILE = 'data/oov_vector.p'\n",
    "embedding = create_wv_embedding_layer(wv, OOV_VECTOR_FILE, max_sequence_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "wv_in (InputLayer)           (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "lambda_lookup (Lambda)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_layer (Embedding)  (None, 100, 50)           20000100  \n",
      "=================================================================\n",
      "Total params: 20,000,100\n",
      "Trainable params: 0\n",
      "Non-trainable params: 20,000,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
    "#     init_op = tf.group(tf.local_variables_initializer())\n",
    "#     sess.run(init_op)\n",
    "vec = embedding.predict(np.array([['python'] * 100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.5897 , -0.55043, -1.0106 , ...,  0.15425, -0.93256,\n",
       "         -0.15025],\n",
       "        [ 0.5897 , -0.55043, -1.0106 , ...,  0.15425, -0.93256,\n",
       "         -0.15025],\n",
       "        [ 0.5897 , -0.55043, -1.0106 , ...,  0.15425, -0.93256,\n",
       "         -0.15025],\n",
       "        ...,\n",
       "        [ 0.5897 , -0.55043, -1.0106 , ...,  0.15425, -0.93256,\n",
       "         -0.15025],\n",
       "        [ 0.5897 , -0.55043, -1.0106 , ...,  0.15425, -0.93256,\n",
       "         -0.15025],\n",
       "        [ 0.5897 , -0.55043, -1.0106 , ...,  0.15425, -0.93256,\n",
       "         -0.15025]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5897  , -0.55043 , -1.0106  ,  0.41226 ,  0.57348 ,  0.23464 ,\n",
       "       -0.35773 , -1.78    ,  0.10745 ,  0.74913 ,  0.45013 ,  1.0351  ,\n",
       "        0.48348 ,  0.47954 ,  0.51908 , -0.15053 ,  0.32474 ,  1.0789  ,\n",
       "       -0.90894 ,  0.42943 , -0.56388 ,  0.69961 ,  0.13501 ,  0.16557 ,\n",
       "       -0.063592,  0.35435 ,  0.42819 ,  0.1536  , -0.47018 , -1.0935  ,\n",
       "        1.361   , -0.80821 , -0.674   ,  1.2606  ,  0.29554 ,  1.0835  ,\n",
       "        0.2444  , -1.1877  , -0.60203 , -0.068315,  0.66256 ,  0.45336 ,\n",
       "       -1.0178  ,  0.68267 , -0.20788 , -0.73393 ,  1.2597  ,  0.15425 ,\n",
       "       -0.93256 , -0.15025 ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv['python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 100\n",
    "\n",
    "_input = tf.keras.layers.Input(shape=(MAX_TOKENS,), dtype=tf.string)\n",
    "x = embedding(_input)\n",
    "x = tf_orig_model(x)\n",
    "\n",
    "model = tf.keras.models.Model(_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_init_op = tf.group([tf.tables_initializer(), tf.local_variables_initializer()], name='legacy_init_op')\n",
    "init_op = tf.group(tf.local_variables_initializer())\n",
    "init_op.run(session=tf.keras.backend.get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf models/blog_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/cole/.virtualenvs/keras-to-tf/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "WARNING:tensorflow:From <ipython-input-17-e38fe1eece46>:11: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: models/blog_model/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'models/blog_model/saved_model.pb'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.set_learning_phase(0)\n",
    "outputs = {'blog_model': model.outputs[0]}\n",
    "signature = tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "    inputs={'tokens': model.input}, outputs=outputs\n",
    "    )\n",
    "builder = tf.saved_model.builder.SavedModelBuilder('models/blog_model')\n",
    "builder.add_meta_graph_and_variables(\n",
    "    sess=tf.keras.backend.get_session(),\n",
    "    tags=[tf.saved_model.tag_constants.SERVING],\n",
    "    signature_def_map={tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature},\n",
    "    legacy_init_op=legacy_init_op\n",
    "    )\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'python ' * 100\n",
    "tokens = text.split()\n",
    "np.array([tokens]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39491233]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array(tokens).reshape((1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5897  , -0.55043 , -1.0106  ,  0.41226 ,  0.57348 ,  0.23464 ,\n",
       "       -0.35773 , -1.78    ,  0.10745 ,  0.74913 ,  0.45013 ,  1.0351  ,\n",
       "        0.48348 ,  0.47954 ,  0.51908 , -0.15053 ,  0.32474 ,  1.0789  ,\n",
       "       -0.90894 ,  0.42943 , -0.56388 ,  0.69961 ,  0.13501 ,  0.16557 ,\n",
       "       -0.063592,  0.35435 ,  0.42819 ,  0.1536  , -0.47018 , -1.0935  ,\n",
       "        1.361   , -0.80821 , -0.674   ,  1.2606  ,  0.29554 ,  1.0835  ,\n",
       "        0.2444  , -1.1877  , -0.60203 , -0.068315,  0.66256 ,  0.45336 ,\n",
       "       -1.0178  ,  0.68267 , -0.20788 , -0.73393 ,  1.2597  ,  0.15425 ,\n",
       "       -0.93256 , -0.15025 ], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv['python']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
